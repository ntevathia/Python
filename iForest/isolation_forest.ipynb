{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to implement the original Isolation Forest algorithm which focus on the anomalies, which are few and different. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for external nodes\n",
    "class exNode:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "# class for internal nodes\n",
    "class inNode:\n",
    "    def __init__(self, left, right, attribute, split_val):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.q = attribute\n",
    "        self.p = split_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IsolationTree class creates a tree and depending on improved value calls the respective functions.\n",
    "# fit_tree is the original method of fitting a tree and fit_improved splits smartly to fit when noise is added to the data.\n",
    "\n",
    "class IsolationTree:\n",
    "    def __init__(self, height_limit):\n",
    "        self.root = None\n",
    "        self.height_limit = height_limit\n",
    "        self.n_nodes = 0\n",
    "\n",
    "    def efficient_split(self, X, size):\n",
    "        \"\"\"\n",
    "        This function randomly checks for new attributes and new value to split the data\n",
    "        and compares which split is better. \n",
    "        Returns : left_data, right_data, q(attribute), p(value)\n",
    "        \"\"\"\n",
    "        mini = X.shape[0]+1 \n",
    "        \n",
    "        # get multiple attributes \n",
    "        Q = np.arange(X.shape[1])\n",
    "        q = np.random.choice(Q, size=size, replace=False) \n",
    "            \n",
    "        for att in q: \n",
    "            min_p = X[:,att].min()      \n",
    "            max_p = X[:,att].max()\n",
    "            if min_p == max_p:  \n",
    "                continue\n",
    "            \n",
    "            # get multiple split values\n",
    "            p = np.random.uniform(min_p, max_p, size)\n",
    "            #p = np.array([min_p + 1, max_p - 1])\n",
    "            \n",
    "            for val in p:\n",
    "                X_left = X[X[:,att] < val]\n",
    "                X_right = X[X[:,att] >= val]\n",
    "                min_count = np.minimum(X_left.shape[0], X_right.shape[0])\n",
    "            \n",
    "                # check for best split\n",
    "                if mini > min_count:   \n",
    "                    mini = min_count\n",
    "                    l_tree_X = X_left\n",
    "                    r_tree_X = X_right\n",
    "                    attribute = att\n",
    "                    value = val\n",
    "            \n",
    "        return l_tree_X, r_tree_X, attribute, value\n",
    "    \n",
    "    \n",
    "    def fit_improved(self, X, length):\n",
    "        \"\"\"\n",
    "        Runs when improved==True\n",
    "        Splits smartly.\n",
    "        \"\"\"\n",
    "        if (length >= self.height_limit) or (X.shape[0] <=1 ): \n",
    "            self.n_nodes += 1\n",
    "            return exNode(X.shape[0])\n",
    "        else:\n",
    "            # when all rows all duplicate\n",
    "            eq = np.all(X == X[0,:], axis = 0)\n",
    "            if (np.ones(X.shape[1])==eq).all():  \n",
    "                self.n_nodes += 1\n",
    "                return exNode(X.shape[0])\n",
    "                \n",
    "            # otherwise\n",
    "            X_left, X_right, q, p = self.efficient_split(X, 3)\n",
    "            self.n_nodes += 1\n",
    "            left_tree = self.fit_tree(X_left, length+1)\n",
    "            right_tree = self.fit_tree(X_right, length+1)\n",
    "            \n",
    "        return inNode(left_tree, right_tree, q, p)\n",
    "    \n",
    "    def fit_tree(self, X, length):\n",
    "        \"\"\"\n",
    "        Runs when improved=False.\n",
    "        \"\"\"\n",
    "        if (length >= self.height_limit) or (X.shape[0] <=1 ): \n",
    "            self.n_nodes += 1\n",
    "            return exNode(X.shape[0])\n",
    "        else:\n",
    "            Q = np.arange(X.shape[1]) # this gives column index\n",
    "            q = np.random.choice(Q)   # choose an attribute randomly\n",
    "            min_p = X[:,q].min()      \n",
    "            max_p = X[:,q].max()\n",
    "            \n",
    "            # all data in Q have same value\n",
    "            if min_p == max_p:\n",
    "                self.n_nodes += 1\n",
    "                return exNode(X.shape[0])\n",
    "            \n",
    "            p = np.random.uniform(min_p, max_p)  # choose p randomly between min and max\n",
    "            X_left = X[X[:,q] < p]\n",
    "            X_right = X[X[:,q] >= p]\n",
    "            \n",
    "            # splitting the tree\n",
    "            self.n_nodes += 1\n",
    "            left_tree = self.fit_tree(X_left, length+1)\n",
    "            right_tree = self.fit_tree(X_right, length+1)\n",
    "        \n",
    "        return inNode(left_tree, right_tree, q, p)\n",
    "        \n",
    "        \n",
    "    def fit(self, X:np.ndarray, improved=False):\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, create an isolation tree. Set field\n",
    "        self.root to the root of that tree and return it.\n",
    "        If you are working on an improved algorithm, check parameter \"improved\"\n",
    "        and switch to your new functionality else fall back on your original code.\n",
    "        \"\"\"\n",
    "        if improved==True:\n",
    "            self.root = self.fit_improved(X, length=0)\n",
    "            return self.root\n",
    "        \n",
    "        self.root = self.fit_tree(X, length=0)\n",
    "        return self.root\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class fits n_trees to form an ensembledTree and calculates score given by approach in the paper.\n",
    "class IsolationTreeEnsemble:\n",
    "    def __init__(self, sample_size, n_trees=10):\n",
    "        self.sample_size = sample_size\n",
    "        self.n_trees = n_trees\n",
    "        self.trees = []  # store all trees here\n",
    "\n",
    "    def fit(self, X:np.ndarray, improved=False):\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, create an ensemble of IsolationTree\n",
    "        objects and store them in a list: self.trees.  Convert DataFrames to\n",
    "        ndarray objects.\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        height_limit = np.ceil(np.log2(self.sample_size))\n",
    "        \n",
    "        # fit n_trees\n",
    "        for i in range(self.n_trees):\n",
    "            X_new = X[np.random.choice(X.shape[0], size=self.sample_size, replace=False)] # take sample and fit a tree on this\n",
    "            tree = IsolationTree(height_limit)\n",
    "            tree.root = tree.fit(X_new, improved)\n",
    "            self.trees.append(tree)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def path_in_one_tree(self, tree, x, height = 0):\n",
    "        \"\"\"\n",
    "        Find path for one instance x in one tree\n",
    "        \"\"\"\n",
    "#         # Recursion way      \n",
    "#         if isinstance(tree, exNode) == True:   # terminal node\n",
    "#             return height + self.get_c(tree.size)\n",
    "#         else:\n",
    "#             attribute = tree.q\n",
    "#             if x[attribute] < tree.p: # visit left tree\n",
    "#                 height += 1\n",
    "#                 left_tree = tree.left\n",
    "#                 height = self.path_in_one_tree(left_tree, x, height)\n",
    "#             elif x[attribute] >= tree.p:                                # visit right tree\n",
    "#                 height += 1\n",
    "#                 right_tree = tree.right\n",
    "#                 height = self.path_in_one_tree(right_tree, x, height)\n",
    "#         return height\n",
    "        \n",
    "        # iterative way\n",
    "        while isinstance(tree, inNode):\n",
    "            attribute = tree.q\n",
    "            if x[attribute] < tree.p:\n",
    "                height += 1\n",
    "                tree = tree.left\n",
    "            else:\n",
    "                height += 1\n",
    "                tree = tree.right\n",
    "                \n",
    "        return height + self.get_c(tree.size)\n",
    "    \n",
    "    def path_length(self, X:np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, X, compute the average path length\n",
    "        for each observation in X.  Compute the path length for x_i using every\n",
    "        tree in self.trees then compute the average for each x_i.  Return an\n",
    "        ndarray of shape (len(X),1).\n",
    "        \"\"\" \n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        path = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i in range(X.shape[0]):         # get x_i   \n",
    "            obs = np.zeros(self.n_trees)\n",
    "            for t in range(self.n_trees):   # get each tree\n",
    "                \n",
    "                # get the parent root of the tree first\n",
    "                obs[t] = self.path_in_one_tree(self.trees[t].root, X[i])  # take height per tree for same obs\n",
    "            path[i] = np.mean(obs)\n",
    "\n",
    "        return path\n",
    "    \n",
    "    \n",
    "    def get_c(self, size):\n",
    "        \"\"\"\n",
    "        Calculates c(n)\n",
    "        \"\"\"\n",
    "    \n",
    "        if size == 2:\n",
    "            return 1\n",
    "        elif size > 2:\n",
    "            H_i = np.log(size-1) + 0.5772156649\n",
    "            return 2*H_i - 2*(size-1)/(size)\n",
    "        \n",
    "        return 0\n",
    "                \n",
    "    def anomaly_score(self, X:np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, X, compute the anomaly score\n",
    "        for each x_i observation, returning an ndarray of them.\n",
    "        \"\"\"\n",
    "\n",
    "        E = self.path_length(X)\n",
    "        c = self.get_c(self.sample_size)\n",
    "        \n",
    "        return 2**(-(E)/c)\n",
    "    \n",
    "    def predict_from_anomaly_scores(self, scores:np.ndarray, threshold:float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given an array of scores and a score threshold, return an array of\n",
    "        the predictions: 1 for any score >= the threshold and 0 otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        return np.where(scores>=threshold, 1, 0)\n",
    "    \n",
    "    def predict(self, X:np.ndarray, threshold:float) -> np.ndarray:\n",
    "        \"A shorthand for calling anomaly_score() and predict_from_anomaly_scores().\"\n",
    "        \n",
    "        score = self.anomaly_score(X)\n",
    "        y_pred = self.predict_from_anomaly_scores(score, threshold)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the threshold (this is data specific), this changes for each dataset.\n",
    "def find_TPR_threshold(y, scores, desired_TPR):\n",
    "    \"\"\"\n",
    "    Start at score threshold 1.0 and work down until we hit desired TPR.\n",
    "    Step by 0.01 score increments. For each threshold, compute the TPR\n",
    "    and FPR to see if we've reached to the desired TPR. If so, return the\n",
    "    score threshold and FPR.\n",
    "    \"\"\"\n",
    "    \n",
    "    threshold = 1.0\n",
    "    prev_FPR = 0\n",
    "    prev_TPR = 0\n",
    "    flag = False\n",
    "    \n",
    "    while flag==False:\n",
    "        y_pred = np.where(scores>=threshold, 1, 0)\n",
    "        confusion = confusion_matrix(y, y_pred)\n",
    "        TN, FP, FN, TP = confusion.flat\n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN)\n",
    "        \n",
    "        # drop threshold only when TPR is small\n",
    "        if TPR < desired_TPR:\n",
    "            prev_FPR = FPR\n",
    "            prev_TPR = TPR\n",
    "            threshold -= 0.01\n",
    "        \n",
    "        # stopping condition\n",
    "        if TPR >= desired_TPR:\n",
    "            flag = True\n",
    "            \n",
    "    # return the one which is nearest to desired_TPR\n",
    "    if np.abs(desired_TPR-TPR) > np.abs(desired_TPR-prev_TPR):\n",
    "        return threshold+0.01, prev_FPR\n",
    "        \n",
    "    return threshold, FPR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The END ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
